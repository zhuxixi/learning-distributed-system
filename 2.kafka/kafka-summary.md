# 深入理解Kafka

## 0 基本概念
### 0.1 broker
1. 一个独立的 Kafka 服务器被称为 broker。 
2. broker接收来自生产者的消息，为消息设置偏移量，并提交消息到磁盘保存。 
3. broker为消费者提供服务，对读取分区的请求作出响应，返回已经提交到磁盘上的消息。
4. **根据特定的硬件及其性能特征，单个 broker 可以轻松处理数千个分区以及每秒
百万级的消息量。**
### 0.2 集群
1. broker是集群的组成部分。
2. 每个集群都有一个 broker 同时充当了**集群控制器**的角色（自动从集群的活跃成员
中选举出来）。
3. **集群控制器**负责管理工作，包括将分区分配给broker和监控broker。
### 0.3 分区
1. 在集群中，一个分区从属于一个broker，该broker被称为**分区的首领**。
2. 一个分区可以分配给多个 broker，这个时候会发生分区复制，
但是**分区的首领只有一个。**
3. 这种复制机制为分区提供了消息冗余，如果有一个broker失效，其他broker
可以接管领导权。不过相关的消费者和生产者都要重新连接到新的首领。
### 0.4 消息
1. Kafka 的数据单元被称为消息。
2. 消息由字节数组组成，消息里的数据没有特别的格式或含义。
3. 消息可以有一个key，key相同的消息会被写到相同的分区上。
### 0.5 分批传输
1. 为了提高效率，消息被分批写入Kafka。
2. 批次就是一组消息，这些消息属于同一个主题和分区。
3. 在时间延迟和吞吐量之间做trade off：批次越大，单位时间内处理的消息就越多，
单条消息的传输时间就越长。
4. 批次数据会被压缩，提升数据的传输和存储能力，但更耗CPU。
### 0.6 schema
1. 我理解就是序列化方式
2. json和xml虽然可读性好，但是兼容性不是很好
3. Avro好像不错，以后可以研究一下
4. 序列化方式不能随便修改，如果否则生产者和消费者都要同步升级
### 0.7 topic和partition
1. Kafka的消息通过topic进行分类。
2. topic可以被分为若干个partition，一个partition就是一个提交日志。
3. 消息以追加的方式写入分区，然后以FIFO的顺序读取。
4. **由于一个topic一般包含几个分区，因此无法在整个topic范围内保证消息的顺序，
但可以保证消息在单个分区内的顺序。**
5. Kafka通过分区来实现数据冗余和伸缩性。
6. 分区可以分布在不同的服务器上，以此来提升性能。
### 0.8 生产者
1. Kafka的客户端就是Kafka系统的用户，它们被分为**生产者**和**消费者**。
2. 生产者创建消息，一个消息会被发布到一个特定的主题上。
3. 生产者在默认情况下把消息均衡地分布到主题的所有分区上
4. **生产者也可以把消息直接写到指定的分区，通过消息键和分区器来实现，分区器为键生
成一个散列值，并将其映射到指定的分区上。这样可以保证包含同一个键的消息会被写到
同一个分区上。**
5. 生产者也可以使用自定义的分区器，根据不同的业务规则将消息映射到分区。
### 0.9 消费者
1. 消费者读取消息。消费者订阅一个或多个主题，并按照消息生成的顺序读取。
2. 消费者通过检查消息的**偏移量（offset）**来区分已经读取过的消息。 
3. 偏移量（offset）是另一种元数据，它是一个不断递增的整数值，在创建消息
时，Kafka会把它添加到消息里。
4. 在给定的分区中，单条消息的偏移量都是**唯一**的。
5. 消费者把每个分区最后读取的消息偏移量保存在Zookeeper或 Kafka上，
如果消费者关闭或重启，它的读取状态不会丢失。
6. 消费者是消费者群组的一部分，会有一个或多个消费者共同读取一个主题。
7. 群组保证每个分区只能被一个消费者使用。**如果一个消费者失效，
群组里的其他消费者可以接管失效消费者的工作。**

## 1 kafka的优势

### 1.1 多个生产者
1个topic可以有多个生产者，同时发。
### 1.2 多个消费者
多个消费者可以组成一个群组，它们共享一个消息流，并保证整个群组对每个给定的消息
只处理一次。
### 1.3 磁盘存储数据
1. Kafka不仅支持多个消费者，还允许消费者非实时地读取消息。
2. 消息被提交到磁盘，根据设置的保留规则进行保存。
3. 每个主题可以设置单独的保留规则，以便满足不同消费者的需求，
各个主题可以保留不同数量的消息。
4. 消费者可能会因为处理速度慢或突发的流量高峰导致无法及时读取消息，
而持久化数据可以保证数据不会丢失。
5. 消费者可以在进行应用程序维护时离线一小段时间，而无需担心消息丢失或堵
塞在生产者端。
6. 消费者可以被关闭，但消息会继续保留在 Kafka 里。消费者可以从上次中
断的地方继续处理消息。
### 1.4 伸缩性
一个包含多个 broker 的集群，即使个别 broker失效，仍然可以持续地为客户提供服务。
支持随时扩展
### 1.5 高性能
上面提到的所有特性，让 Kafka 成为了一个高性能的发布与订阅消息系统。通过横向扩展
生产者、消费者和 broker， Kafka 可以轻松处理巨大的消息流。在处理大量数据的同时，
它还能保证亚秒级的消息延迟。
## 2 broker配置

### 2.1 broker.id
1. 每个broker都需要有一个标识符，使用broker.id来表示。
2. 一般都是将ID号映射到机器名。
### 2.2 port
1. 如果使用默认配置来启动 Kafka，它会监听 9092 端口。
2. 修改 port 配置参数可以把它设置成其他任意可用的端口。
3. 如果使用 1024 以下的端口，需要使用 root 权限启动Kafka，**别这么干**。
### 2.3 zookeeper.connect
1. 用于保存 broker元数据的Zookeeper地址。
2. 一般都要指定Chroot。
### 2.4 log.dirs
1. Kafka把所有消息都保存在磁盘上，存放这些日志片段的目录是通过 log.dirs 指定的。
2. 它是一组用逗号分隔的本地文件系统路径。
3. 如果指定了多个路径，那么 broker 会根据“最少使用”原则，
把同一个分区的日志片段保存到同一个路径下。
4. 要注意， broker 会往拥有最少数目分区的路径新增分区，
而不是往拥有最小磁盘空间的路径新增分区。
### 2.5 num.recovery.threads.per.data.dir
1. 对于如下 3 种情况， Kafka 会使用可配置的线程池来处理日志片段：
* 服务器正常启动，用于打开每个分区的日志片段；
* 服务器崩溃后重启，用于检查和截短每个分区的日志片段；
* 服务器正常关闭，用于关闭日志片段。
2. 默认情况下，每个日志目录只使用一个线程。
3. 因为这些线程只是在服务器启动和关闭时会用到，所以完全可以设置大量的线程
来达到并行操作的目的。
4. 对于包含大量分区的服务器来说，一旦发生崩溃，在进行恢复时使用并行操作可能
会省下数小时的时间。
5. 设置此参数时需要注意，所配置的数字对应的是 log.dirs 指定的单个日志目录。
也就是说，如果 num.recovery.threads.per.data.dir 被设为 8，
并且 log.dir 指定了 3 个路径，那么总共需要 24 个线程。
### 2.6 auto.create.topics.enable
> **这个参数默认是true，要改为false！**
1. 默认情况下， Kafka 会在如下几种情形下自动创建主题：
* 当一个生产者开始往主题写入消息时；
* 当一个消费者开始从主题读取消息时；
* 当任意一个客户端向主题发送元数据请求时。
2. 这些行为都是非预期的，最好别这么搞，建议把
 auto.create.topics.enable 设为 false。

## 3 主题的默认配置
### 3.1 num.partitions
1. num.partitions 参数指定了新创建的主题将包含多少个分区。
2. 该参数的默认值是 1。
3. **我们可以增加主题分区的个数，但不能减少分区的个数。**
4. 拥有大量消息的主题如果要进行负载分散，就需要大量的分区。
### 3.2 如何选定分区数量
在进行数量选择时，需要考虑如下几个因素:
* 主题需要达到多大的吞吐量？例如，是希望每秒钟写入 100KB 还是 1GB ？
* 从单个分区读取数据的最大吞吐量是多少？每个分区一般都会有一个消费
者，如果你知道消费者将数据写入数据库的速度不会超过每秒 50MB，那
么你也该知道，从一个分区读取数据的吞吐量不需要超过每秒 50MB。
* 可以通过类似的方法估算生产者向单个分区写入数据的吞吐量，不过生产
者的速度一般比消费者快得多，所以最好为生产者多估算一些吞吐量。
* 每个 broker 包含的分区个数、可用的磁盘空间和网络带宽。
* 如果消息是按照不同的键来写入分区的，那么为已有的主题新增分区就会
很困难。
* 单个 broker 对分区个数是有限制的，因为分区越多，占用的内存越多，完
成首领选举需要的时间也越长。

> 如果每秒钟要从主题上写入和读取 1GB 的数据，并且每个消费者每秒钟可以处理
50MB的数据，那么至少需要20个分区。这样就可以让 20 个消费者同时读取这些分区，
从而达到每秒钟 1GB 的吞吐量。

### 3.3 log.retention.ms
1. Kafka 通常根据时间来决定数据可以被保留多久。
2. 默认使用 log.retention.hours 参数来配置时间，默认值为 168 小时，也就是一周。
3. 除此以外，还有其他两个参数 log.retention.minutes 和 log.retention.ms。
这 3 个参数的作用是一样的，都是决定消息多久以后会被删除
5. **推荐使用 log.retention.ms。**
6. 如果指定了不止一个参数，Kafka 会优先使用具有最小值的那个参数。

>根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现
的。一般来说，最后修改时间指的就是日志片段的关闭时间，也就是文件里
最后一个消息的时间戳。

### 3.4 log.retention.bytes
1. 还可以通过保留的消息字节数来判断消息是否过期，通过参数 log.
retention.bytes 来指定，作用在每一个分区上。
>如果有一个包含 8 个分区的主题，并且 log.retention.bytes 被设为 1GB，
那么这个主题最多可以保留 8GB 的数据。当主题的分区个数增加时，
整个主题可以保留的数据也随之增加。
### 3.5 消息保留策略
1. 如果同时指定了 log.retention.bytes 和 log.retention.ms（或者另一个时
间参数），只要任意一个条件得到满足，消息就会被删除。
> 例如，假设 log.
retention.ms 设置为 86 400 000（也就是 1 天）， log.retention.bytes 设置
为 1 000 000 000（也就是 1GB），**如果消息字节总数在不到一天的时间就超
过了 1GB，那么多出来的部分就会被删除。相反，如果消息字节总数小于
1GB，那么一天之后这些消息也会被删除，尽管分区的数据总量小于 1GB。**

### 3.6 log.segment.bytes
1. 以上的设置都作用在日志片段上，而不是作用在单个消息上。
2. 当消息到达 broker 时，它们被追加到分区的当前日志片段上。
3. 当日志片段大小达到 log.segment.bytes 指定的上限时，当前日志片段就会被关闭，
一个新的日志片段被打开。
4. **只有一个日志片段被关闭后，才会开始等待过期。**
5. 这个参数的值越小，就会越频繁地关闭和分配新文件，从而降低磁盘写入的整体效率。
6. 如果主题的消息量不大，就需要调整这个参数的大小。
>例如，如果一个主题每天只接收 100MB 的消息，而 log.segment.bytes 使用默认设置，
那么需要10天才能填满一个日志片段。**因为在日志片段被关闭之前消息是不会过期的**，
所以如果 log.retention.ms 被设为 604 800 000（也就是 1 周），
那么日志片段最多需要 17 天才会过期。
这是因为关闭日志片段需要 10 天的时间，而根据配置的过期时间，还需要再保留 7 天时
间（**要等到日志片段里的最后一个消息过期才能被删除**）。

### 3.7 log.segment.ms
1. 指定了多长时间之后日志片段会被关闭。
2. log.segment.bytes 和 log.retention.ms看哪个条件先得到满足。
3. log.segment.ms 没有默认设定值，所以只根据大小来关闭日志片段。
4. **基于时间的日志片段对磁盘性能的是有影响的，需要谨慎配置**

> 在使用基于时间的日志片段时，要着重考虑并行关闭多个日志片段对磁盘性
能的影响。如果多个分区的日志片段永远不能达到大小的上限，就会发生这
种情况，因为 broker 在启动之后就开始计算日志片段的过期时间，对于那些
数据量小的分区来说，日志片段的关闭操作总是同时发生。

5. 所以这个值最好别设置

### 3.8 message.max.bytes
1. 此参数来限制单个消息的大小，该参数指的是压缩后的消息大小。
2. 默认值是1MB。
3. 如果生产者尝试发送的消息超过这个大小，不仅消息不会被接收，还会受到报错异常。
4. **这个值对性能有显著的影响。值越大，那么负责处理网络连接和请求的线程就需要
花越多的时间来处理这些请求。它还会增加磁盘写入块的大小，从而影响 IO 吞吐量。**

### 3.9 服务端和客户端之间的消息大小需要协商！
消费者客户端设置的 fetch.message.max.bytes 必须与服务器端设置的消息
大小进行协商。**如果这个值比 message.max.bytes 小，那么消费者就无法读
取比较大的消息，导致出现消费者被阻塞。** 在为集群里的 broker 配置
replica.fetch.max.bytes 参数时，也要注意这个问题！。

>笔者生产上就遇到过这种情况，message.max.bytes设置的比较大，但是客户端设置的
小。当消费者遇到一条大消息会报错，导致那个partition的消息无法消费。这是很严重的
生产事故，一定要小心。**还有，这个问题锅不是我的，我只是帮忙查了这个问题。**

## 4 硬件的选择
### 4.1 磁盘吞吐量
1. 服务器端磁盘吞吐量的影响生产者发送消息的性能。生产者生成的消息必须被提交
到服务器保存，大多数客户端在发送消息之后会一直等待，直到至少有一个服务器确认消
息已经成功提交为止。
2. 磁盘写入速度越快，生成消息的延迟就越低。
3. 有钱上固态，没钱做raid。
### 4.2 磁盘容量
1. 需要多大的磁盘容量取决于需要保留的消息数量。
2. 存储容量的选择同时受到集群复制策略的影响。
>如果服务器每天会收到 1TB 消息，并且保留 7 天，那么就需要 7TB 的存储空间，
而且还要为其他文件提供至少 10% 的额外空间。除此之外，还需要提供缓冲区，
用于应付消息流量的增长和波动。
### 4.3 内存
1. 磁盘性能影响生产者，而内存影响消费者。
2. 消费者一般从分区尾部读取消息，如果有生产者存在，消费者会直接读取存放在
系统的页面缓存中的消息，这比从磁盘上重新读取要快得多。
3. 运行 Kafka 的 JVM 不需要太大的内存，剩余的系统内存可以用作页面缓存，
或者用来缓存正在使用中的日志片段。
4. 不建议把 Kafka 同其他程序部署在1台机器上，它们需要共享页面缓存，
降低消费者的性能。
### 4.4 网络
1. 网络吞吐量决定了 Kafka 能够处理的最大数据流量。
2. 它和磁盘存储是制约 Kafka 扩展规模的主要因素。 
3. Kafka 支持多个消费者，造成流入和流出的网络流量不平衡，从而让情况变
得更加复杂。
4. 集群复制和镜像也会占用网络流量。
5. 如果网络接口出现饱和，那么集群的复制就会出现延时，整个集群都可能会垮掉。
### 4.5 CPU
与磁盘和内存相比， Kafka 对计算处理能力的要求相对较低。
唯一需要CPU的地方就是解压缩客户端的数据流，然后重新压缩，写到本地磁盘。

## 5 kafka集群
### 5.1 集群的优势
1. 可以跨服务器进行负载均衡。
2. 可以使用复制功能来避免因单点故障造成的数据丢失。
3. 在维护 Kafka 或底层系统时，使用集群可以确保为客户端提供高可用性。

### 5.2 需要多少个broker
1. 需要多少磁盘空间来保留数据，以及单个 broker 有多少空间可用。
>如果整个集群需要保留 10TB 的数据，每个broker 可以存储 2TB，
那么至少需要 5 个 broker。如果启用了数据复制，那么至少还需要
一倍的空间，不过这要取决于配置的复制系数是多少。也就是说，如
果启用了数据复制，那么这个集群至少需要 10 个 broker。

2. 集群处理请求的能力。这通常与网络接口处理客户端流量的能力有
关，特别是当有多个消费者存在或者在数据保留期间流量发生波动（比如高峰时段的流量
爆发）时。
### 5.3 broker配置
1. 所有 broker 都必须配置相同的 zookeeper.connect。
2. 每个 broker 都必须为 broker.id 参数设置唯一的值。

>如果两个 broker 使用相同的broker.id，那么第二个 broker 就无法启动。
### 5.4 操作系统调优
>调优的参数主要与虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。这些参数一般配置在 /etc/sysctl.conf
文件里，不过在对内核参数进行调整时，最好参考操作系统的文档。
#### 5.4.1 虚拟内存
1. 对于大多数依赖吞吐量的应用程序来说，要尽量避免内存交换。
2. 内存页和磁盘之间的交换对 Kafka 各方面的性能都有重大影响。 
3. Kafka 大量地使用系统页面缓存，如果虚拟内存被交换到磁盘，
说明已经没有多余内存可以分配给页面缓存了。
4. 进行内存交换可以防止操作系统由于内存不足而突然终止进程。
5. 建议把 vm.swappiness 参数的值设置得小一点，比如 1。
6. 要优先考虑减小页面缓存，而不是进行内存交换。
>为什么不把 vm.swappiness 设为零
先前，人们建议尽量把 vm.swapiness 设为 0，它意味着“除非发生内存溢
出，否则不要进行内存交换”。直到 Linux 内核 3.5-rc1 版本发布，这个值的
意义才发生了变化。这个变化被移植到其他的发行版上，包括 Red Hat 企业
版内核 2.6.32-303。在发生变化之后， 0 意味着“在任何情况下都不要发生交
换”。所以现在建议把这个值设为 1。

7. 日志片段一般要保存在快速磁盘上，不管是SSD还是Raid。
8. 减少脏页的数量，这个可以通过将 vm.dirty_background_ratio
设为小于 10 的值来实现。该值指的是系统内存的百分比，大部分情况下设为 5 就可以
了。它不应该被设为 0，因为那样会促使内核频繁地刷新页面，从而降低内核为底层设备的
磁盘写入提供缓冲的能力。
通过设置 vm.dirty_ratio 参数可以增加被内核进程刷新到磁盘之前的脏页数量，
可以将它设为大于 20 的值（这也是系统内存的百分比）。这个值可设置的范围很广，
60~80 是个比较合理的区间。不过调整这个参数会带来一些风险，
包括未刷新磁盘操作的数量和同步刷新引起的长时间 I/O 等待。
**如果该参数设置了较高的值，建议启用 Kafka 的复制功能，避免因系统崩溃造
成数据丢失。**
9. 为了给这些参数设置合适的值，最好是在 Kafka 集群运行期间检查脏页的数量，
不管是在生存环境还是模拟环境。
可以在 /proc/vmstat 文件里查看当前脏页数量。
```
# cat /proc/vmstat | egrep "dirty|writeback"
nr_dirty 3875
nr_writeback 29
nr_writeback_temp 0
#
```
#### 5.4.2 磁盘






















